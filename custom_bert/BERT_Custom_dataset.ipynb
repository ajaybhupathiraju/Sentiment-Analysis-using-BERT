{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "951695cb-bb44-4d02-9216-6175ad499115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datasets import load_dataset\n",
    "from transformers import TFBertModel,TFBertForSequenceClassification,BertTokenizerFast,BertForSequenceClassification\n",
    "import keras\n",
    "from transformers import create_optimizer\n",
    "import pandas as pd\n",
    "import string\n",
    "from keras.layers import TextVectorization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "882fe153-3f88-494b-9c2b-132207774772",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=1000\n",
    "SEQUENCE_LENGTH = 512\n",
    "BATCH_SIZE=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "012027e0-ff2c-4dd3-9381-389c08c796ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"G:\\Ajay\\dataset\\IMDB Movie dataset\\IMDB Dataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7129c8b0-b6e3-4d25-a605-176ff74a1091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_text(text):\n",
    "    text=text.translate(str.maketrans('', '',string.punctuation))\n",
    "    return text.lower()\n",
    "\n",
    "def change_sentiment(sentiment):\n",
    "    if sentiment == \"positive\":\n",
    "       return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c30d40cb-2452-474d-b437-6808c44b5f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"review\"]=data[\"review\"].apply(lambda x:cleanup_text(x))\n",
    "data[\"sentiment\"]=data[\"sentiment\"].apply(lambda x:change_sentiment(x))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d3428d2-e23e-4015-8832-26f2e4f8f123",
   "metadata": {},
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "844360e3-43c9-4516-9a8b-d3073bee8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e59f7e2b-310d-40e6-8360-a0bae5b7bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'],padding=True,max_length=512,truncation=True,return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a4f707f-eaad-472a-8f0d-987d94b5c680",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"review\"]\n",
    "Y = data[\"sentiment\"]\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=0,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "99909b9a-5edb-476c-bdf9-e4f4f33682ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'train':Dataset.from_dict({'text':x_train.tolist(),'label':y_train.tolist()}),\n",
    "    'test':Dataset.from_dict({'text':x_test.tolist(),'label':y_test.tolist()})}\n",
    "dataset=DatasetDict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebb35e46-27a2-45da-9352-446a7b7ed9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 40000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2063cc76-c6e5-4704-916a-9b1aad22679f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████| 40000/40000 [00:08<00:00, 4635.88 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████| 10000/10000 [00:02<00:00, 4610.02 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset=dataset.map(preprocess_function,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7d6cde5-6a99-46b1-9b4e-cedb61695deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 40000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "003244e8-a223-4371-86ca-6648eed54a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_dataset = dataset[\"train\"].to_tf_dataset(\n",
    "    columns=[\"input_ids\",\"token_type_ids\",\"attention_mask\",\"label\"],\n",
    "    shuffle=True,\n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "tf_val_dataset = dataset[\"test\"].to_tf_dataset(\n",
    "    columns=[\"input_ids\",\"token_type_ids\",\"attention_mask\",\"label\"],\n",
    "    shuffle=True,\n",
    "    batch_size=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a213672-fc6e-461e-b227-380ea521a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_positions(dataset):\n",
    "    return {\n",
    "        \"input_ids\":dataset[\"input_ids\"],\n",
    "        \"token_type_ids\":dataset[\"token_type_ids\"],\n",
    "        \"attention_mask\":dataset[\"attention_mask\"],\n",
    "        \"labels\":dataset[\"label\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ca2f5c2-2d29-4fed-97f0-54b979c0e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_dataset = tf_train_dataset.map(swap_positions)\n",
    "tf_val_dataset = tf_val_dataset.map(swap_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74600ee7-ee53-45f5-a6a4-e0f8f3530fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_epochs :3\n",
      "batch_per_epoch :10000\n",
      "total_train_steps :30000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "BATCH_SIZE = 4\n",
    "batch_per_epoch = int(len(dataset[\"train\"])//BATCH_SIZE)\n",
    "total_train_steps = int(batch_per_epoch*num_epochs)\n",
    "print(\"num_epochs :{}\".format(num_epochs))\n",
    "print(\"batch_per_epoch :{}\".format(batch_per_epoch))\n",
    "print(\"total_train_steps :{}\".format(total_train_steps))\n",
    "opt,scheduler = create_optimizer(init_lr=2e-5,num_train_steps=total_train_steps,num_warmup_steps=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a04990f4-768d-446f-88a7-5f5a193c1ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=2)\n",
    "model.compile(optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91e711f6-ecd8-4863-a472-da65206e14c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4000/4000 [==============================] - 2838s 706ms/step - loss: 0.2229 - accuracy: 0.9100 - val_loss: 0.1784 - val_accuracy: 0.9318\n",
      "Epoch 2/2\n",
      "4000/4000 [==============================] - 2790s 698ms/step - loss: 0.1102 - accuracy: 0.9620 - val_loss: 0.2448 - val_accuracy: 0.9262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x178d1ec1460>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tf_train_dataset,validation_data=tf_val_dataset,epochs=2,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "12967c43-24d2-4009-a2a1-f595caf1ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./custom_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "985fa26b-103a-4994-aca4-9b55c75b7bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ./custom_bert were not used when initializing TFBertForSequenceClassification: ['dropout_113']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at ./custom_bert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# model = BertModel.from_pretrained(\"./custom_bert\")\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"./custom_bert\",num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "349b4864-55c0-453b-bdc4-165fd2b56ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review is -> positive\n",
      "review is -> negetive\n"
     ]
    }
   ],
   "source": [
    "class_labels = [\"negetive\",\"positive\"]\n",
    "review_text = [\"This movie looks very integresting and a great job\",\"Movie is too length and not at all good\"]\n",
    "inputs =tokenizer(review_text,padding=True,return_tensors=\"tf\")\n",
    "logits = model(**inputs).logits\n",
    "result = np.argmax(logits,axis=1)\n",
    "for i,val in enumerate(result):\n",
    "    print(\"review is -> {}\".format(class_labels[val]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
